{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classification Example with TensorFlow\n",
    "\n",
    "This notebook is a companion of [A Visual and Interactive Guide to the Basics of Neural Networks](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/).\n",
    "\n",
    "This is an example of how to do classification on a simple dataset in TensorFlow. Basically, we're building a model to help a friend choose a house to buy. She has given us the table below of houses and whether she likes them or not. We're to build a model that takes a house area and number of bathrooms as input, and outputs a prediction of whether she would like the house or not.\n",
    "\n",
    "| Area (sq ft) (x1) | Bathrooms (x2) | Label (y) |\n",
    " | --- | --- | --- |\n",
    " | 2,104 |  3 | Good |\n",
    " | 1,600 |  3 | Good |\n",
    " | 2,400 |  3 | Good |\n",
    " | 1,416 | \t2 | Bad |\n",
    " | 3,000 | \t4 | Bad |\n",
    " | 1,985 | \t4 | Good |\n",
    " | 1,534 | \t3 | Bad |\n",
    " | 1,427 | \t3 | Good |\n",
    " | 1,380 | \t3 | Good |\n",
    " | 1,494 | \t3 | Good |\n",
    " \n",
    " \n",
    " \n",
    " We'll start by loading our favorite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline               \n",
    "import pandas as pd              # A beautiful library to help us work with data as tables\n",
    "import numpy as np               # So we can use number matrices. Both pandas and TensorFlow need it. \n",
    "import matplotlib.pyplot as plt  # Visualize the things\n",
    "import tensorflow as tf          # Fire from the gods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then load the house data CSV. Pandas is an incredible library that gives us great flexibility in dealing with table-like data. We load tables (or csv files, or excel sheets) into a \"data frame\", and process it however we like. You can think of it as a programatic way to do a lot of the things you previously did with Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calories Burned</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Minutes Sedentary</th>\n",
       "      <th>Minutes Lightly Active</th>\n",
       "      <th>Minutes Fairly Active</th>\n",
       "      <th>Minutes Very Active</th>\n",
       "      <th>Activity Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2615</td>\n",
       "      <td>5527</td>\n",
       "      <td>4.41</td>\n",
       "      <td>739</td>\n",
       "      <td>153</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2372</td>\n",
       "      <td>5175</td>\n",
       "      <td>3.61</td>\n",
       "      <td>806</td>\n",
       "      <td>118</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3045</td>\n",
       "      <td>9914</td>\n",
       "      <td>7.52</td>\n",
       "      <td>577</td>\n",
       "      <td>238</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2245</td>\n",
       "      <td>2245</td>\n",
       "      <td>1.56</td>\n",
       "      <td>897</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2940</td>\n",
       "      <td>6629</td>\n",
       "      <td>5.23</td>\n",
       "      <td>622</td>\n",
       "      <td>171</td>\n",
       "      <td>77</td>\n",
       "      <td>46</td>\n",
       "      <td>1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3114</td>\n",
       "      <td>7061</td>\n",
       "      <td>4.92</td>\n",
       "      <td>528</td>\n",
       "      <td>110</td>\n",
       "      <td>116</td>\n",
       "      <td>68</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2642</td>\n",
       "      <td>6293</td>\n",
       "      <td>4.39</td>\n",
       "      <td>598</td>\n",
       "      <td>183</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2229</td>\n",
       "      <td>1941</td>\n",
       "      <td>1.35</td>\n",
       "      <td>697</td>\n",
       "      <td>132</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2481</td>\n",
       "      <td>4583</td>\n",
       "      <td>3.77</td>\n",
       "      <td>803</td>\n",
       "      <td>86</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2313</td>\n",
       "      <td>1804</td>\n",
       "      <td>1.26</td>\n",
       "      <td>762</td>\n",
       "      <td>119</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2845</td>\n",
       "      <td>6137</td>\n",
       "      <td>4.34</td>\n",
       "      <td>696</td>\n",
       "      <td>187</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2967</td>\n",
       "      <td>8072</td>\n",
       "      <td>5.63</td>\n",
       "      <td>678</td>\n",
       "      <td>147</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2946</td>\n",
       "      <td>8954</td>\n",
       "      <td>6.78</td>\n",
       "      <td>658</td>\n",
       "      <td>142</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2940</td>\n",
       "      <td>9740</td>\n",
       "      <td>6.79</td>\n",
       "      <td>754</td>\n",
       "      <td>172</td>\n",
       "      <td>41</td>\n",
       "      <td>73</td>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2446</td>\n",
       "      <td>5135</td>\n",
       "      <td>3.58</td>\n",
       "      <td>701</td>\n",
       "      <td>146</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3128</td>\n",
       "      <td>11044</td>\n",
       "      <td>8.17</td>\n",
       "      <td>605</td>\n",
       "      <td>149</td>\n",
       "      <td>76</td>\n",
       "      <td>92</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1686</td>\n",
       "      <td>268</td>\n",
       "      <td>0.19</td>\n",
       "      <td>947</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2536</td>\n",
       "      <td>5932</td>\n",
       "      <td>4.13</td>\n",
       "      <td>844</td>\n",
       "      <td>193</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2765</td>\n",
       "      <td>8820</td>\n",
       "      <td>6.15</td>\n",
       "      <td>751</td>\n",
       "      <td>164</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2989</td>\n",
       "      <td>10819</td>\n",
       "      <td>7.54</td>\n",
       "      <td>651</td>\n",
       "      <td>174</td>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "      <td>1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2737</td>\n",
       "      <td>6110</td>\n",
       "      <td>4.26</td>\n",
       "      <td>766</td>\n",
       "      <td>136</td>\n",
       "      <td>58</td>\n",
       "      <td>49</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2432</td>\n",
       "      <td>3760</td>\n",
       "      <td>2.62</td>\n",
       "      <td>777</td>\n",
       "      <td>151</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2808</td>\n",
       "      <td>7672</td>\n",
       "      <td>5.40</td>\n",
       "      <td>671</td>\n",
       "      <td>145</td>\n",
       "      <td>68</td>\n",
       "      <td>41</td>\n",
       "      <td>1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2316</td>\n",
       "      <td>5250</td>\n",
       "      <td>3.66</td>\n",
       "      <td>943</td>\n",
       "      <td>111</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2942</td>\n",
       "      <td>7100</td>\n",
       "      <td>5.35</td>\n",
       "      <td>724</td>\n",
       "      <td>141</td>\n",
       "      <td>130</td>\n",
       "      <td>43</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2976</td>\n",
       "      <td>8744</td>\n",
       "      <td>6.09</td>\n",
       "      <td>674</td>\n",
       "      <td>170</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3121</td>\n",
       "      <td>10706</td>\n",
       "      <td>7.96</td>\n",
       "      <td>660</td>\n",
       "      <td>167</td>\n",
       "      <td>55</td>\n",
       "      <td>85</td>\n",
       "      <td>1719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2757</td>\n",
       "      <td>8711</td>\n",
       "      <td>6.07</td>\n",
       "      <td>926</td>\n",
       "      <td>187</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2602</td>\n",
       "      <td>5940</td>\n",
       "      <td>4.59</td>\n",
       "      <td>790</td>\n",
       "      <td>176</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2645</td>\n",
       "      <td>8764</td>\n",
       "      <td>6.11</td>\n",
       "      <td>948</td>\n",
       "      <td>191</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>1427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Calories Burned  Steps  Distance  Minutes Sedentary  \\\n",
       "0              2615   5527      4.41                739   \n",
       "1              2372   5175      3.61                806   \n",
       "2              3045   9914      7.52                577   \n",
       "3              2245   2245      1.56                897   \n",
       "4              2940   6629      5.23                622   \n",
       "5              3114   7061      4.92                528   \n",
       "6              2642   6293      4.39                598   \n",
       "7              2229   1941      1.35                697   \n",
       "8              2481   4583      3.77                803   \n",
       "9              2313   1804      1.26                762   \n",
       "10             2845   6137      4.34                696   \n",
       "11             2967   8072      5.63                678   \n",
       "12             2946   8954      6.78                658   \n",
       "13             2940   9740      6.79                754   \n",
       "14             2446   5135      3.58                701   \n",
       "15             3128  11044      8.17                605   \n",
       "16             1686    268      0.19                947   \n",
       "17             2536   5932      4.13                844   \n",
       "18             2765   8820      6.15                751   \n",
       "19             2989  10819      7.54                651   \n",
       "20             2737   6110      4.26                766   \n",
       "21             2432   3760      2.62                777   \n",
       "22             2808   7672      5.40                671   \n",
       "23             2316   5250      3.66                943   \n",
       "24             2942   7100      5.35                724   \n",
       "25             2976   8744      6.09                674   \n",
       "26             3121  10706      7.96                660   \n",
       "27             2757   8711      6.07                926   \n",
       "28             2602   5940      4.59                790   \n",
       "29             2645   8764      6.11                948   \n",
       "\n",
       "    Minutes Lightly Active  Minutes Fairly Active  Minutes Very Active  \\\n",
       "0                      153                     42                   31   \n",
       "1                      118                     21                   27   \n",
       "2                      238                     43                   41   \n",
       "3                      174                      0                    0   \n",
       "4                      171                     77                   46   \n",
       "5                      110                    116                   68   \n",
       "6                      183                     25                   31   \n",
       "7                      132                     21                    5   \n",
       "8                       86                     44                   38   \n",
       "9                      119                     45                   14   \n",
       "10                     187                     62                   42   \n",
       "11                     147                     64                   74   \n",
       "12                     142                     66                   69   \n",
       "13                     172                     41                   73   \n",
       "14                     146                     17                   31   \n",
       "15                     149                     76                   92   \n",
       "16                      20                      0                    0   \n",
       "17                     193                     25                   17   \n",
       "18                     164                     40                   54   \n",
       "19                     174                     37                   77   \n",
       "20                     136                     58                   49   \n",
       "21                     151                     20                   20   \n",
       "22                     145                     68                   41   \n",
       "23                     111                     30                   24   \n",
       "24                     141                    130                   43   \n",
       "25                     170                     63                   66   \n",
       "26                     167                     55                   85   \n",
       "27                     187                     30                   49   \n",
       "28                     176                     34                   29   \n",
       "29                     191                     48                   51   \n",
       "\n",
       "    Activity Calories  \n",
       "0                1134  \n",
       "1                 816  \n",
       "2                1659  \n",
       "3                 709  \n",
       "4                1532  \n",
       "5                1710  \n",
       "6                1132  \n",
       "7                 670  \n",
       "8                 939  \n",
       "9                 856  \n",
       "10               1458  \n",
       "11               1548  \n",
       "12               1559  \n",
       "13               1559  \n",
       "14                965  \n",
       "15               1808  \n",
       "16                 78  \n",
       "17               1095  \n",
       "18               1348  \n",
       "19               1593  \n",
       "20               1262  \n",
       "21                902  \n",
       "22               1323  \n",
       "23                813  \n",
       "24               1591  \n",
       "25               1561  \n",
       "26               1719  \n",
       "27               1304  \n",
       "28               1169  \n",
       "29               1427  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"input.csv\") # Let's have Pandas load our dataset as a dataframe\n",
    "dataframe = dataframe.drop([\"Date\", \"Floors\"], axis=1) # Remove columns we don't care about\n",
    "dataframe = dataframe.replace({',': ''}, regex=True)\n",
    "dataframe = dataframe.apply(pd.to_numeric)\n",
    "dataframe # Let's have the notebook show us how the dataframe looks now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe now only has the features. Let's introduce the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>BAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WELL  BAD\n",
       "0      0    1\n",
       "1      1    0\n",
       "2      1    0\n",
       "3      0    1\n",
       "4      0    1\n",
       "5      1    0\n",
       "6      1    0\n",
       "7      1    0\n",
       "8      1    0\n",
       "9      1    0\n",
       "10     0    1\n",
       "11     0    1\n",
       "12     0    1\n",
       "13     0    1\n",
       "14     0    1\n",
       "15     1    0\n",
       "16     0    1\n",
       "17     0    1\n",
       "18     0    1\n",
       "19     0    1\n",
       "20     0    1\n",
       "21     0    1\n",
       "22     1    0\n",
       "23     0    1\n",
       "24     0    1\n",
       "25     0    1\n",
       "26     0    1\n",
       "27     0    1\n",
       "28     0    1\n",
       "29     0    1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sleep = 8 * 60 # Sleep for 8 hours\n",
    "labels = pd.read_csv(\"output.csv\") # Let's have Pandas load our dataset as a dataframe\n",
    "labels = labels.drop([\"Date\", \"Minutes Awake\", \"Number of Awakenings\", \"Time in Bed\"], axis=1) # Remove columns we don't care about\n",
    "labels[\"WELL\"] = (labels['Minutes Asleep'] >= target_sleep).astype(int)\n",
    "labels.loc[:, (\"BAD\")] = labels[\"WELL\"] == 0           # y2 is the negation of y1\n",
    "labels.loc[:, (\"BAD\")] = labels[\"BAD\"].astype(int)    # Turn TRUE/FALSE values into 1/0\n",
    "labels = labels.drop([\"Minutes Asleep\"], axis=1) # Remove columns we don't care about\n",
    "labels # Let's have the notebook show us how the dataframe looks now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our data in the dataframe, we'll need to shape it in matrices to feed it to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputX = dataframe.as_matrix()\n",
    "inputY = labels.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now our input matrix looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.61500000e+03,   5.52700000e+03,   4.41000000e+00,\n",
       "          7.39000000e+02,   1.53000000e+02,   4.20000000e+01,\n",
       "          3.10000000e+01,   1.13400000e+03],\n",
       "       [  2.37200000e+03,   5.17500000e+03,   3.61000000e+00,\n",
       "          8.06000000e+02,   1.18000000e+02,   2.10000000e+01,\n",
       "          2.70000000e+01,   8.16000000e+02],\n",
       "       [  3.04500000e+03,   9.91400000e+03,   7.52000000e+00,\n",
       "          5.77000000e+02,   2.38000000e+02,   4.30000000e+01,\n",
       "          4.10000000e+01,   1.65900000e+03],\n",
       "       [  2.24500000e+03,   2.24500000e+03,   1.56000000e+00,\n",
       "          8.97000000e+02,   1.74000000e+02,   0.00000000e+00,\n",
       "          0.00000000e+00,   7.09000000e+02],\n",
       "       [  2.94000000e+03,   6.62900000e+03,   5.23000000e+00,\n",
       "          6.22000000e+02,   1.71000000e+02,   7.70000000e+01,\n",
       "          4.60000000e+01,   1.53200000e+03],\n",
       "       [  3.11400000e+03,   7.06100000e+03,   4.92000000e+00,\n",
       "          5.28000000e+02,   1.10000000e+02,   1.16000000e+02,\n",
       "          6.80000000e+01,   1.71000000e+03],\n",
       "       [  2.64200000e+03,   6.29300000e+03,   4.39000000e+00,\n",
       "          5.98000000e+02,   1.83000000e+02,   2.50000000e+01,\n",
       "          3.10000000e+01,   1.13200000e+03],\n",
       "       [  2.22900000e+03,   1.94100000e+03,   1.35000000e+00,\n",
       "          6.97000000e+02,   1.32000000e+02,   2.10000000e+01,\n",
       "          5.00000000e+00,   6.70000000e+02],\n",
       "       [  2.48100000e+03,   4.58300000e+03,   3.77000000e+00,\n",
       "          8.03000000e+02,   8.60000000e+01,   4.40000000e+01,\n",
       "          3.80000000e+01,   9.39000000e+02],\n",
       "       [  2.31300000e+03,   1.80400000e+03,   1.26000000e+00,\n",
       "          7.62000000e+02,   1.19000000e+02,   4.50000000e+01,\n",
       "          1.40000000e+01,   8.56000000e+02],\n",
       "       [  2.84500000e+03,   6.13700000e+03,   4.34000000e+00,\n",
       "          6.96000000e+02,   1.87000000e+02,   6.20000000e+01,\n",
       "          4.20000000e+01,   1.45800000e+03],\n",
       "       [  2.96700000e+03,   8.07200000e+03,   5.63000000e+00,\n",
       "          6.78000000e+02,   1.47000000e+02,   6.40000000e+01,\n",
       "          7.40000000e+01,   1.54800000e+03],\n",
       "       [  2.94600000e+03,   8.95400000e+03,   6.78000000e+00,\n",
       "          6.58000000e+02,   1.42000000e+02,   6.60000000e+01,\n",
       "          6.90000000e+01,   1.55900000e+03],\n",
       "       [  2.94000000e+03,   9.74000000e+03,   6.79000000e+00,\n",
       "          7.54000000e+02,   1.72000000e+02,   4.10000000e+01,\n",
       "          7.30000000e+01,   1.55900000e+03],\n",
       "       [  2.44600000e+03,   5.13500000e+03,   3.58000000e+00,\n",
       "          7.01000000e+02,   1.46000000e+02,   1.70000000e+01,\n",
       "          3.10000000e+01,   9.65000000e+02],\n",
       "       [  3.12800000e+03,   1.10440000e+04,   8.17000000e+00,\n",
       "          6.05000000e+02,   1.49000000e+02,   7.60000000e+01,\n",
       "          9.20000000e+01,   1.80800000e+03],\n",
       "       [  1.68600000e+03,   2.68000000e+02,   1.90000000e-01,\n",
       "          9.47000000e+02,   2.00000000e+01,   0.00000000e+00,\n",
       "          0.00000000e+00,   7.80000000e+01],\n",
       "       [  2.53600000e+03,   5.93200000e+03,   4.13000000e+00,\n",
       "          8.44000000e+02,   1.93000000e+02,   2.50000000e+01,\n",
       "          1.70000000e+01,   1.09500000e+03],\n",
       "       [  2.76500000e+03,   8.82000000e+03,   6.15000000e+00,\n",
       "          7.51000000e+02,   1.64000000e+02,   4.00000000e+01,\n",
       "          5.40000000e+01,   1.34800000e+03],\n",
       "       [  2.98900000e+03,   1.08190000e+04,   7.54000000e+00,\n",
       "          6.51000000e+02,   1.74000000e+02,   3.70000000e+01,\n",
       "          7.70000000e+01,   1.59300000e+03],\n",
       "       [  2.73700000e+03,   6.11000000e+03,   4.26000000e+00,\n",
       "          7.66000000e+02,   1.36000000e+02,   5.80000000e+01,\n",
       "          4.90000000e+01,   1.26200000e+03],\n",
       "       [  2.43200000e+03,   3.76000000e+03,   2.62000000e+00,\n",
       "          7.77000000e+02,   1.51000000e+02,   2.00000000e+01,\n",
       "          2.00000000e+01,   9.02000000e+02],\n",
       "       [  2.80800000e+03,   7.67200000e+03,   5.40000000e+00,\n",
       "          6.71000000e+02,   1.45000000e+02,   6.80000000e+01,\n",
       "          4.10000000e+01,   1.32300000e+03],\n",
       "       [  2.31600000e+03,   5.25000000e+03,   3.66000000e+00,\n",
       "          9.43000000e+02,   1.11000000e+02,   3.00000000e+01,\n",
       "          2.40000000e+01,   8.13000000e+02],\n",
       "       [  2.94200000e+03,   7.10000000e+03,   5.35000000e+00,\n",
       "          7.24000000e+02,   1.41000000e+02,   1.30000000e+02,\n",
       "          4.30000000e+01,   1.59100000e+03],\n",
       "       [  2.97600000e+03,   8.74400000e+03,   6.09000000e+00,\n",
       "          6.74000000e+02,   1.70000000e+02,   6.30000000e+01,\n",
       "          6.60000000e+01,   1.56100000e+03],\n",
       "       [  3.12100000e+03,   1.07060000e+04,   7.96000000e+00,\n",
       "          6.60000000e+02,   1.67000000e+02,   5.50000000e+01,\n",
       "          8.50000000e+01,   1.71900000e+03],\n",
       "       [  2.75700000e+03,   8.71100000e+03,   6.07000000e+00,\n",
       "          9.26000000e+02,   1.87000000e+02,   3.00000000e+01,\n",
       "          4.90000000e+01,   1.30400000e+03],\n",
       "       [  2.60200000e+03,   5.94000000e+03,   4.59000000e+00,\n",
       "          7.90000000e+02,   1.76000000e+02,   3.40000000e+01,\n",
       "          2.90000000e+01,   1.16900000e+03],\n",
       "       [  2.64500000e+03,   8.76400000e+03,   6.11000000e+00,\n",
       "          9.48000000e+02,   1.91000000e+02,   4.80000000e+01,\n",
       "          5.10000000e+01,   1.42700000e+03]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our labels matrix looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputY = inputY.reshape(-1, 1)\n",
    "inputY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare some parameters for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "training_epochs = 200000\n",
    "display_step = 5000\n",
    "n_samples = inputY.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to define the TensorFlow operations. Notice that this is a declaration step where we tell TensorFlow how the prediction is calculated. If we execute it, no calculation would be made. It would just acknowledge that it now knows how to do the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 8])   # Okay TensorFlow, we'll feed you an array of examples. Each example will\n",
    "                                            # be an array of two float values (area, and number of bathrooms).\n",
    "                                            # \"None\" means we can feed you any number of examples\n",
    "                                            # Notice we haven't fed it the values yet\n",
    "            \n",
    "W = tf.Variable(tf.zeros([8, 2]))           # Maintain a 2 x 2 float matrix for the weights that we'll keep updating \n",
    "                                            # through the training process (make them all zero to begin with)\n",
    "    \n",
    "b = tf.Variable(tf.zeros([2]))              # Also maintain two bias values\n",
    "\n",
    "y_values = tf.add(tf.matmul(x, W), b)       # The first step in calculating the prediction would be to multiply\n",
    "                                            # the inputs matrix by the weights matrix then add the biases\n",
    "    \n",
    "y = tf.nn.softmax(y_values)                 # Then we use softmax as an \"activation function\" that translates the\n",
    "                                            # numbers outputted by the previous layer into probability form\n",
    "    \n",
    "y_ = tf.placeholder(tf.float32, [None,2])   # For training purposes, we'll also feed you a matrix of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify our cost function and use Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cost function: Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(y_ - y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-149-ebd23cbb6ad2>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Initialize variabls and tensorflow session\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Drum roll*\n",
    "\n",
    "And now for the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step: 0000 cost= 0.150000006\n",
      "Training step: 5000 cost= 0.150000006\n",
      "Training step: 10000 cost= 0.150000006\n",
      "Training step: 15000 cost= 0.150000006\n",
      "Training step: 20000 cost= 0.150000006\n",
      "Training step: 25000 cost= 0.150000006\n",
      "Training step: 30000 cost= 0.150000006\n",
      "Training step: 35000 cost= 0.150000006\n",
      "Training step: 40000 cost= 0.150000006\n",
      "Training step: 45000 cost= 0.150000006\n",
      "Training step: 50000 cost= 0.150000006\n",
      "Training step: 55000 cost= 0.150000006\n",
      "Training step: 60000 cost= 0.150000006\n",
      "Training step: 65000 cost= 0.150000006\n",
      "Training step: 70000 cost= 0.150000006\n",
      "Training step: 75000 cost= 0.150000006\n",
      "Training step: 80000 cost= 0.150000006\n",
      "Training step: 85000 cost= 0.150000006\n",
      "Training step: 90000 cost= 0.150000006\n",
      "Training step: 95000 cost= 0.150000006\n",
      "Training step: 100000 cost= 0.150000006\n",
      "Training step: 105000 cost= 0.150000006\n",
      "Training step: 110000 cost= 0.150000006\n",
      "Training step: 115000 cost= 0.150000006\n",
      "Training step: 120000 cost= 0.150000006\n",
      "Training step: 125000 cost= 0.150000006\n",
      "Training step: 130000 cost= 0.150000006\n",
      "Training step: 135000 cost= 0.150000006\n",
      "Training step: 140000 cost= 0.150000006\n",
      "Training step: 145000 cost= 0.150000006\n",
      "Training step: 150000 cost= 0.150000006\n",
      "Training step: 155000 cost= 0.150000006\n",
      "Training step: 160000 cost= 0.150000006\n",
      "Training step: 165000 cost= 0.150000006\n",
      "Training step: 170000 cost= 0.150000006\n",
      "Training step: 175000 cost= 0.150000006\n",
      "Training step: 180000 cost= 0.150000006\n",
      "Training step: 185000 cost= 0.150000006\n",
      "Training step: 190000 cost= 0.150000006\n",
      "Training step: 195000 cost= 0.150000006\n",
      "Optimization Finished!\n",
      "Training cost= 0.15 W= [[ -1.37985090e-03   1.38016080e-03]\n",
      " [ -3.66150006e-03   3.66150006e-03]\n",
      " [ -2.61041691e-06   2.61041691e-06]\n",
      " [ -4.40218806e-04   4.40251897e-04]\n",
      " [ -8.30416757e-05   8.30416757e-05]\n",
      " [ -1.99999995e-05   1.99999995e-05]\n",
      " [ -2.38750017e-05   2.38750017e-05]\n",
      " [ -6.42208324e-04   6.42208324e-04]] b= [ -5.22737196e-07   5.22737196e-07] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(training_epochs):  \n",
    "    sess.run(optimizer, feed_dict={x: inputX, y_: inputY}) # Take a gradient descent step using our inputs and labels\n",
    "\n",
    "    # That's all! The rest of the cell just outputs debug messages. \n",
    "    # Display logs per epoch step\n",
    "    if (i) % display_step == 0:\n",
    "        cc = sess.run(cost, feed_dict={x: inputX, y_:inputY})\n",
    "        print \"Training step:\", '%04d' % (i), \"cost=\", \"{:.9f}\".format(cc) #, \\\"W=\", sess.run(W), \"b=\", sess.run(b)\n",
    "\n",
    "print \"Optimization Finished!\"\n",
    "training_cost = sess.run(cost, feed_dict={x: inputX, y_: inputY})\n",
    "print \"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now the training is done. TensorFlow is now holding on to our trained model (Which is basically just the defined operations, plus the variables W and b that resulted from the training process).\n",
    "\n",
    "Is a cost value of 0.109537 good or bad? I have no idea. At least it's better than the first cost value of 0.114958666. Let's use the model on our dataset to see how it does, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.29202034e-22,   1.00000000e+00],\n",
       "       [  8.42769978e-21,   1.00000000e+00],\n",
       "       [  4.52256456e-37,   1.00000000e+00],\n",
       "       [  2.61883761e-11,   1.00000000e+00],\n",
       "       [  1.93388111e-26,   1.00000000e+00],\n",
       "       [  4.40430760e-28,   1.00000000e+00],\n",
       "       [  8.80797812e-25,   1.00000000e+00],\n",
       "       [  3.19818366e-10,   1.00000000e+00],\n",
       "       [  4.09291630e-19,   1.00000000e+00],\n",
       "       [  5.14812415e-10,   1.00000000e+00],\n",
       "       [  9.48859252e-25,   1.00000000e+00],\n",
       "       [  4.32387823e-31,   1.00000000e+00],\n",
       "       [  7.20989368e-34,   1.00000000e+00],\n",
       "       [  2.12250827e-36,   1.00000000e+00],\n",
       "       [  8.30280278e-21,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  5.24124247e-04,   9.99475896e-01],\n",
       "       [  1.40016421e-23,   1.00000000e+00],\n",
       "       [  3.82262387e-33,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.89974390e-24,   1.00000000e+00],\n",
       "       [  2.06476629e-16,   1.00000000e+00],\n",
       "       [  1.68865116e-29,   1.00000000e+00],\n",
       "       [  5.05831527e-21,   1.00000000e+00],\n",
       "       [  5.19378095e-28,   1.00000000e+00],\n",
       "       [  3.02484414e-33,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  7.84968091e-33,   1.00000000e+00],\n",
       "       [  1.05151467e-23,   1.00000000e+00],\n",
       "       [  6.06567060e-33,   1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y, feed_dict={x: inputX })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So It's guessing they're all good houses. That makes it get 7/10 correct. Not terribly impressive. A model with a hidden layer should do better, I guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Btw, this is how I calculated the softmax values in the post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26894143,  0.7310586 ], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.softmax([1., 2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
